# -*- coding: utf-8 -*-
"""BinaryClassification_MyModel.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1k-j4C9JOsnkn0AvTPLBJPtlM1WEeB6A5
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import numpy as np
import cv2
import torch
from torch.utils.data import Dataset
import torchvision.transforms.functional as TF

class DriveDataset(Dataset):
    def __init__(self, images_path, labels):

        self.images_path = images_path
        self.labels = labels
        self.n_samples = len(images_path)

    def __getitem__(self, index):
        """ Reading image """
        image = cv2.imread(self.images_path[index], cv2.IMREAD_COLOR)
        image = image/255.0 
        image = cv2.resize(np.float32(image),size,interpolation = cv2.INTER_NEAREST ) ## (256, 256, 3)
        image = np.transpose(image, (2, 0, 1))  ## (3, 256, 256)
        image = image.astype(np.float32)
        image = torch.from_numpy(image)
        # image = TF.normalize(image,mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])

        """ Reading classification Label """
        label = self.labels[index]
        
        return image, label

    def __len__(self):
        return self.n_samples

import os
import time
import random
import numpy as np
import cv2
import torch

""" Seeding the randomness. """
def seeding(seed):
    random.seed(seed)
    os.environ["PYTHONHASHSEED"] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True

""" Create a directory. """
def create_dir(path):
    if not os.path.exists(path):
        os.makedirs(path)

""" Calculate the time taken """
def epoch_time(start_time, end_time):
    elapsed_time = end_time - start_time
    elapsed_mins = int(elapsed_time / 60)
    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))
    return elapsed_mins, elapsed_secs

import torch
import torch.nn as nn
import torch.nn.functional as F

class CustomBCELoss:

    def __init__(self):
      self.bce = nn.BCELoss()

    def __call__(self, yhat, ys):
      yhat = torch.sigmoid(yhat)
      yhat = yhat.view(-1)
      ys = ys.view(-1)
      # print("After Sigmoid: ", yhat, ys)
      yhat, ys = yhat.float(), ys.float()
    
      return self.bce(yhat, ys)

# from model import build_unet 
import torch
import torch.nn as nn
import torch.nn.functional as F


class conv_block(nn.Module):
    def __init__(self, in_c, out_c):
        super().__init__()

        self.conv1 = nn.Conv2d(in_c, out_c, kernel_size = 3, padding = 1)
        self.bn1 = nn.BatchNorm2d(out_c)

        self.conv2 = nn.Conv2d(out_c, out_c, kernel_size = 3, padding = 1)
        self.bn2 = nn.BatchNorm2d(out_c)

        self.relu = nn.ReLU()

    def forward(self, inputs):
        x = self.conv1(inputs)
        x = self.bn1(x)
        x = self.relu(x)

        x = self.conv2(x)
        x = self.bn2(x)
        x = self.relu(x)

        return x

class encoder_block(nn.Module):
    def __init__(self, in_c, out_c):
        super().__init__()

        self.conv = conv_block(in_c, out_c)
        self.pool = nn.MaxPool2d((2, 2))

    def forward(self, inputs):
        x = self.conv(inputs)
        p = self.pool(x)

        return p

class decoder_block(nn.Module):
    def __init__(self, in_c, out_c):
        super().__init__()

        self.up = nn.ConvTranspose2d(in_c, out_c, kernel_size=2, stride=2, padding=0)
        self.conv = conv_block(out_c+out_c, out_c)

    def forward(self, inputs, skip):
        x = self.up(inputs)
        x = torch.cat([x, skip], axis=1)
        x = self.conv(x)
        return x

class binary_Classification(nn.Module):
    def __init__(self):
        super().__init__()

        """ Classification classifier """
        self.e1 = encoder_block(3,64)
        # self.e2 = encoder_block(64, 128)
        # self.b = conv_block(64, 128)
        # self.e5 = encoder_block(128,256)
        self.global_avg = nn.AdaptiveAvgPool2d(1)
        self.fc1 = nn.Linear(64, 64)
        self.fc2 = nn.Linear(64, 32)   
        self.fc3 = nn.Linear(32, 1)       ### ---> 2nd dimension is the number of classification labels
        self.sigmoid = nn.Sigmoid()

    def forward(self, inputs):

        """ Diagnostic branch """
        p1 = self.e1(inputs)
        # p2 = self.e2(p1)
        # b = self.b(p2)
        # p5 = self.e5(p2)
        avg = self.global_avg(p1)
        avg = avg.view(avg.size(0), -1)
        fc1 = self.fc1(avg)
        fc2 = self.fc2(fc1)
        fc3 = self.fc3(fc2)
        label = self.sigmoid(fc3)

        return label

import pandas as pd
from itertools import repeat

df1 = pd.read_csv('/content/drive/MyDrive/YNET/SkinCancerData/TrainLabels.csv')
df2 = pd.read_csv('/content/drive/MyDrive/YNET/SkinCancerData/ValLabels.csv')
df3 = pd.read_csv('/content/drive/MyDrive/YNET/SkinCancerData/TestLabels.csv')
trainLabels, validLabels, testLabels = [], [], []
trainLabels = df1['NV'].astype(int).tolist()
validLabels = df2['NV'].astype(int).tolist()
testLabels = df3['NV'].astype(int).tolist()

print(len(trainLabels),len(validLabels),len(testLabels))

import os
import time
from glob import glob

import torch
from torch.utils.data import DataLoader
from collections import OrderedDict
import torchvision.models as models
import torch.nn as nn
import gc
import torch.optim as optim

def train(model, loader, optimizer, loss_fn, device):
    epoch_loss = 0.0

    model.train()
    for x, y in loader:
        torch.cuda.empty_cache()
        x = x.to(device, dtype=torch.float32)
        y = y.to(device, dtype=torch.float32)
        
        optimizer.zero_grad()
        y_pred = model(x)
        y_pred = y_pred.view(-1)
        # y_pred, y = y_pred.int(), y.int()
        # print(y_pred, y)
        loss = loss_fn(y_pred, y)
        loss.backward()
        optimizer.step()
        epoch_loss += loss.item()

    epoch_loss = epoch_loss/len(loader)
    return epoch_loss


def evaluate(model, loader, loss_fn, device):
    epoch_loss = 0.0

    model.eval()
    with torch.no_grad():
        for x, y in loader:
            x = x.to(device, dtype=torch.float32)
            y = y.to(device, dtype=torch.float32)

            y_pred = model(x)
            y_pred = y_pred.view(-1)
  
            loss = loss_fn(y_pred, y)
            epoch_loss += loss.item()

        epoch_loss = epoch_loss/len(loader)
    return epoch_loss


if __name__ == "__main__":
    """ Seeding """
    # seeding(42)

    """ Directories """
    create_dir("/content/drive/MyDrive/YNET/SavedModel")

    """ Load dataset """
    train_x = sorted(glob("/content/drive/MyDrive/YNET/SkinCancerData/TrainImages925/*"))
    
    valid_x = sorted(glob("/content/drive/MyDrive/YNET/SkinCancerData/ValImages/*"))

    data_str = f"Dataset Size:\nTrain: {len(train_x)} - Valid: {len(valid_x)}\n"
    print(data_str)

    """ Hyperparameters """
    H = 256
    W = 256
    size = (H, W)
    batch_size = 5
    num_epochs = 150
    lr = 1e-5
    checkpoint_path = "/content/drive/MyDrive/YNET/SavedModel/BCMyModelCheckpoint925.pth"

    """ Dataset and loader """
    train_dataset = DriveDataset(train_x, trainLabels)
    valid_dataset = DriveDataset(valid_x, validLabels)

    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=1)

    valid_loader = DataLoader(dataset=valid_dataset, batch_size=batch_size, shuffle=True, num_workers=1)
    
    trainLoss = []
    validLoss = []
    device = torch.device('cuda')   ## GTX 1060 6GB
    model = binary_Classification()
    model = model.to(device)

    # optimizer = torch.optim.Adam(model.parameters(), lr=lr)
    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.8)
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, verbose=True)
    loss_fn = nn.BCELoss()

    """ Training the model """
    best_valid_loss = float("inf")

    for epoch in range(num_epochs):
        start_time = time.time()

        train_loss = train(model, train_loader, optimizer, loss_fn, device)
        valid_loss = evaluate(model, valid_loader, loss_fn, device)

        trainLoss.append(train_loss)
        validLoss.append(valid_loss)

        """ Saving the model """
        if valid_loss < best_valid_loss:
            data_str = f"Valid loss improved from {best_valid_loss:2.4f} to {valid_loss:2.4f}. Saving checkpoint: {checkpoint_path}"
            print(data_str)

            best_valid_loss = valid_loss
            torch.save(model.state_dict(), checkpoint_path)

        end_time = time.time()
        epoch_mins, epoch_secs = epoch_time(start_time, end_time)

        data_str = f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\n'
        data_str += f'\tTrain Loss: {train_loss:.3f}\n'
        data_str += f'\t Val. Loss: {valid_loss:.3f}\n'
        print(data_str)

import matplotlib.pyplot as plt
import numpy as np

x = np.arange(150)
plt.plot(x, trainLoss, color='r', label='Train Loss')
plt.plot(x, validLoss, color='b', label='Valid Loss')
plt.title('Training & Validation Loss over 75 epochs')
plt.ylabel('values')
plt.xlabel('epochs')
plt.legend()
plt.show()

import os, time
from operator import add
import numpy as np
from glob import glob
import cv2
from tqdm import tqdm
import imageio
import torch
import matplotlib as plt
from sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay
from sklearn.metrics import classification_report



def calculate_metrics(y_true, y_pred):

  confusionM = confusion_matrix(y_pred, y_true)
  score_jaccard = jaccard_score(y_true, y_pred)
  score_f1 = f1_score(y_true, y_pred)
  score_recall = recall_score(y_true, y_pred)
  score_precision = precision_score(y_true, y_pred)
  score_acc = accuracy_score(y_true, y_pred)
  target_names = ['class 0', 'class 1']
  cr = classification_report(y_true, y_pred, target_names=target_names)
  return [score_jaccard, score_f1, score_recall, score_precision, score_acc, confusionM], cr

if __name__ == "__main__":
  """ Seeding """
  # seeding(42)

  """ Folders """
  create_dir("/content/drive/MyDrive/YNET/SavedModel")

  """ Load dataset """
  test_x = sorted(glob("/content/drive/MyDrive/YNET/SkinCancerData/TestImages/*"))
  
  """ Hyperparameters """
  H = 256
  W = 256
  size = (W, H)
  checkpoint_path = "/content/drive/MyDrive/YNET/SavedModel/BCMyModelCheckpoint925.pth"

  """ Load the checkpoint """
  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
  model =  binary_Classification()
  model1 = model.to(device)
  model1.load_state_dict(torch.load(checkpoint_path, map_location=device))
  model1.eval()

  metrics_score = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  time_taken = []
  predicted_labels = []

  for i, (x, y) in tqdm(enumerate(zip(test_x, testLabels)), total=len(test_x)):
    """ Extract the name """
    name = x.split("/")[-1].split(".")[0]

    """ Reading image """
    image = cv2.imread(x, cv2.IMREAD_COLOR) ## (256, 256, 3)
    image = cv2.resize(image, size)
    x = np.transpose(image, (2, 0, 1))      ## (3, 256, 256)
    x = x/255.0
    x = np.expand_dims(x, axis=0)           ## (1, 3, 256, 256)
    x = x.astype(np.float32)
    x = torch.from_numpy(x)
    x = x.to(device)


    with torch.no_grad():
      """ Prediction and Calculating FPS """
      start_time = time.time()
      pred_label = model1(x)
      # pred_label = torch.sigmoid(pred_label)
      pred_label = 1 if pred_label > 0.5 else 0
      predicted_labels.append(pred_label)

      total_time = time.time() - start_time
      time_taken.append(total_time)

  truthlabels = []
  for i in range(len(testLabels)):
    truthlabels.append(testLabels[i])
  score, cr = calculate_metrics(predicted_labels, truthlabels)
  metrics_score = list(map(add, metrics_score, score))
   
  jaccard = metrics_score[0]/len(test_x)
  f1 = metrics_score[1]/len(test_x)
  recall = metrics_score[2]/len(test_x)
  precision = metrics_score[3]/len(test_x)
  acc = metrics_score[4]/len(test_x)
  confM = metrics_score[5]/len(test_x)
  # cr = metrics_score[6]/len(test_x)

  print(f"Jaccard: {jaccard:1.4f} - F1: {f1:1.4f} - Recall: {recall:1.4f} - Precision: {precision:1.4f} - Acc: {acc:1.4f}")
  print("Classification Report : ", cr)
  print("Predcited labels: ", predicted_labels)
  print("True labels: ", truthlabels)
  print("Confusion Matrix: ", confusion_matrix(predicted_labels,truthlabels))

  disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(predicted_labels,truthlabels), display_labels=[0,1])
  disp.plot()
  # plt.show()

  fps = 1/np.mean(time_taken)
  print("FPS: ", fps)